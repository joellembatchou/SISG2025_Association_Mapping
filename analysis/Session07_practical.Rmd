---
title: "Practical 7 - Rare Variant Analysis"
author: ""
date: ""
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---
Before you begin:

* Make sure that R is installed on your computer
* For this lab, we will use the following R libraries:
```{r load-libs, message=FALSE, warning=FALSE}
library(data.table)
library(dplyr)
library(BEDMatrix)
library(SKAT)
library(ACAT)
library(ggplot2)
```

## Introduction
We will look into a dataset collected on a quantitative phenotype which was first analyzed through GWAS and a signal was detected in a region on chromosome 1. Let's determine whether the signal is present when we focus on rare variation at the locus. In our analyses, ***we will define rare variants as those with $MAF \leq 5\%$***.

The file ["rv_pheno.txt"](https://github.com/joellembatchou/SISG2024_Association_Mapping/tree/master/data)” contains the phenotype measurements for a set of individuals and the file ["rv_geno_chr1.bed"](https://github.com/joellembatchou/SISG2024_Association_Mapping/tree/master/data) is a binary file in PLINK BED format with accompanying BIM and FAM files which contains the genotype data.

### Data preparation
Let’s first load the files into the R session. We first need to define the path to the directory containing the phenotype and genotype files **(change the path to the files location on your machine)**.
```{r echo=FALSE}
files_dir <- "/Users/joelle.mbatchou/SISG/2024/SISG2024_Association_Mapping/data/" 
plink2_binary <- "/Users/joelle.mbatchou/software/bins/plink2" 
```

```{r eval=FALSE}
files_dir <- "/SISGM19/data/" 
```

Also specify the paths to the PLINK2 binary:
```{r eval=FALSE}
plink2_binary <- "/SISGM19/bin/plink2" 
```

We can now read the phenotype file:
```{r}
pheno_file <- fread(sprintf("%s/rv_pheno.txt", files_dir), header = TRUE) 
head(pheno_file, 3)
```

## Exercises
1.  Using PLINK, extract **rare variants** in a new PLINK BED file.
We use options `--max-maf` to select rare variants and `--maj-ref force` so that the minor allele is the effect allele.
```{r, eval = FALSE}
# first fill in the thresholds to use for each filter
filter_maf = 

cmd <- sprintf('%s --bfile "%s/rv_geno_chr1" --max-maf %g --maj-ref force --make-bed --out chr1_region_rv', plink2_binary, files_dir, filter_maf)
system(cmd)
```
This generates a new set of PLINK BED genotype files containing only the variants that passed the MAF filter `chr1_region_rv.{bed,bim,fam}`.
  

2. Import the data files in R.

* Read the genotype data using R function `BEDMatrix()`. We use option `simple_names = TRUE` to easily filter by sample IDs later.
```{r, eval = FALSE}
G <- BEDMatrix("chr1_region_rv", simple_names = TRUE)
```

* Keep only samples who are present both in the genotype as well as phenotype data and who don't have missing values for the phenotype.
```{r, eval = FALSE}
# identify ID of samples with non-missing phenotypes
ids.keep <- with(pheno_file, IID[ !is.na(Pheno) ])
# subset the genotype & phenotype data based on IDs
G <- G[match(ids.keep, rownames(G)), ]
pheno_file <- pheno_file[match(ids.keep, pheno_file$IID), ] 
```

3. Examine the genotype data:
  * Compute the minor allele frequency (MAF) for each SNP and plot histogram. We use the `colMeans()` function to G and specify the argument na.rm = TRUE in case missing genotypes are present.
```{r, eval = FALSE}
# Recall the MAF formula: maf(g) = sum(g) / (2*N) = mean(g) / 2
maf <- colMeans(G, na.rm=TRUE)/2
# we can use the 'hist' function in R to plot histograms
hist(maf)
```

4. Run the single variant association tests in PLINK (only for the extracted variants).
```{r, eval = FALSE}
cmd <- sprintf("%s --bfile chr1_region_rv --pheno %s/rv_pheno.txt --pheno-name Pheno --glm allow-no-covars  --out test_plink", plink2_binary, files_dir)
system(cmd)
sv_pvals <- fread("test_plink.Pheno.glm.linear")
str(sv_pvals) # what variables are used to store p-values and effect sizes?
```

  * What would be your significance threshold after applying Bonferroni correction for the multiple tests (assume the nominal significance level is 0.05)? Is anything significant after this correction?
```{r, eval = FALSE}

# determine the appropriate significance threshold
bonf_threshold <- 
sv_pvals[ sv_pvals$P < bonf_threshold, ]
```
  
  * Make a volcano plot (i.e. plot log10 p-values against the effect sizes). Which of the Burden/SKAT/ACAT tests do you expect will give us most power? 

```{r, eval = FALSE}
# volcano plot hint: to make a scatterplot of variable var2 against var1 stored in the data frame, you can use:
with(sv_pvals, plot(x=var1, y=var2)) # change 'var1' and 'var2' to the right names in sv_pvals
```


5. We will first compare three collapsing/burden approaches:
  * CAST (Binary collapsing approach): for each individual, count if they have a rare allele at any of the sites
  * MZ Test/GRANVIL (Count based collapsing): for each individual, count the total number of sites where a rare allele is present
  * Weighted burden test: for each individual, take a weighted count of the rare alleles across sites (for the weights, use `weights <- dbeta(MAF, 1, 25)`)

For each approach, first need to generate the burden scores. 
```{r eval=FALSE}
# CAST : count number of rare alleles for each person and determine if it is > 0
sum_alleles_per_sample <- rowSums(G)
burden.cast <- as.numeric( sum_alleles_per_sample > 0 )

# MZ : count number of sites with rare alleles for each person
burden.mz <- rowSums(G > 0)

# Weighted burden : weighted sum of genotype counts across sites
weights <- dbeta(maf, 1, 25) 
burden.weighted <- G %*% weights
```

Run a test for association between the phenotype and each burden score using the `lm()` R function, e.g.
```{r eval=FALSE}
# e.g. for CAST
summary(lm(pheno_file$Pheno ~ burden.cast))
```
Are there notable differences across the test results?

6. Now use SKAT to test for an association. 
```{r, eval = FALSE}
# first fit the null model
skat.null <- SKAT_Null_Model( pheno_file$Pheno ~ 1 , out_type = "C")
# Run SKAT association test (returns a list - p-value is in `$p.value`)
skat_sumstats <- SKAT(G, skat.null )
str(skat_sumstats)
skat_sumstats$p.value
```

7. Run the omnibus SKAT, but consider setting $\rho$ (i.e.`r.corr`) to 0 and then 1. 
  * Compare the results to using the CAST,MZ/GRANVIL and Weighted burden collapsing approaches in Question 5 as well as SKAT in Question 6. What tests do these $\rho$ values correspond to?
```{r, eval = FALSE}
# Example for rho = 0
rho <- 0
skat_sumstats_rho <- SKAT(G, skat.null, r.corr = rho )
skat_sumstats_rho$p.value
```

8. Now consider the omnibus version of SKAT, but use the “optimal.adj” approach which searches across a range of rho values.
```{r, eval = FALSE}
# Run SKATO association test using grid of rho values
skat_sumstats_rho_grid <- SKAT(G, skat.null, method="optimal.adj")
skat_sumstats_rho_grid$p.value
```

9. Run ACATV on the single variant p-values.
The basic command would look like
```{r, eval = FALSE}
# `weights` vector is from Question 5
acat.weights <- weights * weights * maf * (1 - maf)
ACAT(sv_pvals$P, weights = acat.weights)
```

10. Run ACATO combining the SKAT and BURDEN p-values (from Question 7) with the ACATV p-value (from Question 9).
```{r, eval = FALSE}
# Fill in the p-values
SKAT_pvalue <- 
Burden_pvalue <- 
ACATV_pvalue <-
# compute ACATO
ACAT( c(SKAT_pvalue, Burden_pvalue, ACATV_pvalue) )
```

### Extra

You can explore the impact of different genetic architectures by analyzing 3 simulated phenotypes in ["data/rv_pheno_extended.txt"](https://gatech.box.com/s/espcwnlibsw62xoiqska9ib9iccxs5fk). More specifically, you can run the same analyses done above for each of these traits and compare the performance of the tests relative to how variant effects were simulated:

* "Pheno_sparse": a single causal variant (i.e. sparse genetic architecture)
* "Pheno_burden_skat": 60% of the variant are causal, and they all have positive effects on the trait
* "Pheno_skat": 20% of the variants are causal and the effect direction (+/-) is randomly assigned